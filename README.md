# ğŸ–ï¸ American Sign Language Recognition ğŸ¤Ÿ  

Welcome to the **American Sign Language Recognition** project! This project recognizes hand signs from the **American Sign Language (ASL)** alphabet using a machine learning model trained with custom image data.  

---

## ğŸ“Œ Features  
âœ… **Custom Hand Sign Dataset** â€“ Collected using a built-in script.  
âœ… **Trained Deep Learning Model** â€“ Uses Google Teachable Machine (`keras_model.h5`).  
âœ… **Real-time Sign Recognition** â€“ Displays recognized sign on screen.  
âœ… **Speech Feature** â€“ Speaks out the recognized sign when pressing `S` key.  

---

## ğŸ“‚ Project Structure  
ğŸ“ Sign-Language-Recognition

â”‚â”€â”€ ğŸ“ Data/ # Contains images of hand signs (A-Z)

â”‚â”€â”€ ğŸ“ Train Model/ # Stores trained model (keras_model.h5)

â”‚â”€â”€ ğŸ“ data_collection.py # Script to collect images for dataset

â”‚â”€â”€ ğŸ“ test.py # Main script to run the recognition

â”‚â”€â”€ ğŸ“ speech.py # Experimental file for voice features

â”‚â”€â”€ ğŸ“ README.md # Project Documentation


---

## ğŸ› ï¸ Installation & Setup  

### ğŸ“Œ Prerequisites  
**ğŸ”¹ Python Version:** This project requires **Python 3.8.10**.  
**ğŸ”¹ Install Required Libraries:** Run the following command to install all dependencies:  
```sh
pip install opencv-python cvzone numpy pyttsx3
```
---

## âœ… Required Python Libraries  

Before running the project, ensure you have the following libraries installed. If not, install them using the provided command.

```sh
pip install opencv-python cvzone numpy pyttsx3
```
### ğŸ“Œ Importing necessary libraries
```
import cv2  # OpenCV for image processing
from cvzone.HandTrackingModule import HandDetector  # Hand detection module
from cvzone.ClassificationModule import Classifier  # Classification module for model prediction
import numpy as np  # Numerical operations
import math  # Math operations
import time  # Time module for delay functions
import pyttsx3  # Text-to-speech conversion
```
---

## ğŸš€ How to Use  

### 1ï¸âƒ£ Collect Your Own Data  

To collect images for training, run "data collection.py" file.
- A window will open showing a box on the screen.
- Place your hand inside the box and press "S" on your keyboard to capture an image.
- The number of collected images will be displayed in the terminal.
- The images will be stored in the Data/ folder inside their respective subfolders (A-Z).
- Recommendation: Collect at least 500+ images per letter for better accuracy.

### 2ï¸âƒ£ Train the Model
- The model was trained using Google Teachable Machine.
- After collecting enough images, upload them to Google Teachable Machine and train the model.
- Export the trained model as a .h5 file.
- Move the generated keras_model.h5 file into the Train Model/ folder.

### 3ï¸âƒ£ Run Sign Recognition
- Run test.py file to Start real-time recognition:
- Press "S" to hear the letter spoken aloud

### 3ï¸âƒ£ Speech.py
speech.py is just file for try and error purpose, where you can experiment other things if you want, it has nothing to do with others.

## ğŸ“¢ Contributing
Want to improve this project? Feel free to fork, improve, and submit a PR! ğŸš€
